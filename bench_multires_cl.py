# bench_multires_cl.py
import os
# CRITICAL FIX: Use abspath. 
# The Compiler Daemon runs in a separate process/context. If we pass it a relative 
# path like "./.inductor_cache", it looks relative to *itself*, not this script.
# Absolute paths ensure the daemon finds the C++ files generated by this script.
#os.environ["TORCHINDUCTOR_CACHE_DIR"] = os.path.abspath("./.inductor_cache")
import inductor_cas_client
# Hook the ZMQ compiler backend immediately
inductor_cas_client.install_cas_client() 

import torch
import torch.nn.functional as F
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import os
import sys
from pathlib import Path

from diffusion_utils import get_schedule, get_alpha_sigma, BucketManager
from dataset import CompositeIterator
from model import HybridGemmaDiT

class ExperimentLogger:
    def __init__(self, output_dir="."):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        script_path = Path(sys.argv[0])
        self.script_name = script_path.stem
        existing = list(self.output_dir.glob(f"{self.script_name}_run_*"))
        if existing:
            run_nums = [int(p.stem.split('_run_')[1].split('_')[0]) for p in existing]
            self.run_id = max(run_nums) + 1
        else:
            self.run_id = 0
        self.figure_count = 0
        self.run_dir = self.output_dir / f"{self.script_name}_run_{self.run_id:03d}"
        self.run_dir.mkdir(exist_ok=True)
        print(f"üìä Experiment: {self.script_name} | Run: {self.run_id} | Dir: {self.run_dir}")
        
    def save_figure(self, fig, name=None):
        if name is None: name = f"fig{self.figure_count}"
        filename = f"{name}.png"
        filepath = self.run_dir / filename
        fig.savefig(filepath, dpi=150, bbox_inches='tight')
        plt.close(fig)
        self.figure_count += 1
        return filepath

def get_image_spans(resolution):
    """
    Helper to generate span metadata for a single 2D continuous latent (image).
    """
    # PATCH FIX: Adjust for model stride
    latent_res = resolution // 2
    length = latent_res * latent_res
    # Standard format: 1 span, not causal (bidirectional), with 2D shape
    return [{'len': length, 'shape': (latent_res, latent_res), 'causal': False}]

def visualize_dataset_samples(iterator, resolutions, samples_per_res=8):
    """
    Generate samples from the composite iterator and label them.
    """
    fig, axes = plt.subplots(len(resolutions), samples_per_res, 
                            figsize=(samples_per_res * 1.5, len(resolutions) * 1.8))
    
    # Handle single resolution case (axes is 1D)
    if len(resolutions) == 1: 
        axes = axes.reshape(1, -1)
    
    for row_idx, res in enumerate(resolutions):
        # Generate batch
        samples = iterator.generate_batch(samples_per_res, res, num_tiles=4.0)
        labels = iterator.last_labels.cpu().numpy()
        samples = samples.cpu()
        
        for col_idx in range(samples_per_res):
            ax = axes[row_idx, col_idx]
            ax.imshow(samples[col_idx].permute(1, 2, 0).clamp(0, 1))
            ax.axis('off')
            
            # Get label name
            lbl_idx = labels[col_idx]
            lbl_name = iterator.label_map.get(lbl_idx, "Unknown")
            
            if col_idx == 0:
                ax.set_title(f"{res}px\n{lbl_name}", fontsize=8, loc='left')
            else:
                ax.set_title(f"{lbl_name}", fontsize=7)
                
    plt.suptitle("Composite Dataset Samples", fontsize=14)
    plt.tight_layout()
    return fig

def warmup_model(model, buckets):
    print("üî• Warming up compilation cache...")
    # 1. Warmup Training Graph
    model.train()
    for res, bs in buckets:
        print(f"   ...compiling train graph for {res}px")
        # Create dummy inputs
        z = torch.randn(bs, 3, res, res, device='cuda')
        t = torch.rand(bs, device='cuda')
        logsnr = get_schedule(t)
        spans = get_image_spans(res)
        
        # Run one step (Forward + Backward)
        opt = torch.optim.AdamW(model.parameters())
        opt.zero_grad()
        out, _, _ = model(z, logsnr, spans)
        loss = out.mean()
        loss.backward()
        opt.step()
        opt.zero_grad() # cleanup

    # 2. Warmup Inference Graph
    model.eval()
    with torch.no_grad():
        for res, _ in buckets: # BS doesn't strictly matter for shape generalization usually
            print(f"   ...compiling inference graph for {res}px")
            z = torch.randn(2, 3, res, res, device='cuda') # Small batch
            logsnr = get_schedule(torch.rand(2, device='cuda'))
            spans = get_image_spans(res)
            model(z, logsnr, spans)
    model.train()
    print("‚úÖ Warmup complete. No more stalls expected.")

def train_multires(mode, buckets, steps=1000, embed_dim=256, depth=12, logger=None):
    """
    Generalized training loop accepting dynamic buckets.
    """
    device = torch.device('cuda')
    print(f"\n--- Training: {mode.upper()} ---")
    print(f"    Buckets (Res, Batch): {buckets}")
    
    model = HybridGemmaDiT(mode, embed_dim=embed_dim, depth=depth).to(device)
    #model = torch.compile(model, dynamic=True)
    model = torch.compile(model, dynamic=True)
    warmup_model(model, buckets)
        
    # Standard Params
    opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)
    
    # Configure Composite Dataset
    mix_config = {'checkerboard': 0.5, 'torus': 0.5}
    iterator = CompositeIterator(device, config=mix_config)
    
    manager = BucketManager(buckets)
    history = []
    
    pbar = tqdm(range(steps), desc=f"{mode}")
    for i in pbar:
        opt.zero_grad()
        res, bs = manager.next_bucket()
        
        # Generate mixed batch
        x0 = iterator.generate_batch(bs, res, num_tiles=4.0)
        labels = iterator.last_labels # [B]
        
        t = torch.rand(bs, device=device).clamp(0.001, 0.999)
        logsnr = get_schedule(t)
        alpha, sigma = get_alpha_sigma(logsnr)
        
        eps = torch.randn_like(x0)
        z_t = x0 * alpha.view(-1,1,1,1) + eps * sigma.view(-1,1,1,1)
        v_true = alpha.view(-1,1,1,1) * eps - sigma.view(-1,1,1,1) * x0

        spans = get_image_spans(res)
        
        # Forward
        raw, l_pred, aux_loss = model(z_t, logsnr, spans)
        
        if mode == 'factorized':
            sigma_p = torch.sqrt(torch.sigmoid(-l_pred)).view(-1, 1, 1, 1)
            v_pred = raw * sigma_p
        else:
            v_pred = raw
            
        # Detailed Loss Calculation
        loss_elem = F.mse_loss(v_pred, v_true, reduction='none').mean(dim=[1,2,3])
        total_loss = loss_elem.mean()
        
        total_loss.backward()
        opt.step()
        
        # --- LOGGING ---
        step_stats = {'step': i, 'res': res, 'loss_total': total_loss.item()}
        
        # Breakdown by dataset type
        for idx, name in iterator.label_map.items():
            mask = (labels == idx)
            if mask.any():
                step_stats[f'loss_{name}'] = loss_elem[mask].mean().item()
            else:
                step_stats[f'loss_{name}'] = None 
                
        history.append(step_stats)
        
        if i % 100 == 0:
            pbar.set_postfix({'loss': f'{total_loss.item():.4f}', 'res': res})
            
    return pd.DataFrame(history), model

@torch.no_grad()
def sample_viz(model, res, num_samples=8):
    model.eval()
    z = torch.randn(num_samples, 3, res, res, device='cuda')
    ts = torch.linspace(1.0, 0.001, 50, device='cuda')

    # Pre-generate spans once (static for sampling loop)
    spans = get_image_spans(res)
    for i in range(49):
        t = ts[i]; t_n = ts[i+1]
        logsnr = get_schedule(torch.full((num_samples,), t, device='cuda'))
        # Pass spans
        raw, l_pred, _ = model(z, logsnr, spans)
        if model.mode == 'factorized':
            sigma_p = torch.sqrt(torch.sigmoid(-l_pred)).view(-1,1,1,1)
            v_pred = raw * sigma_p
        else:
            v_pred = raw
        logsnr_n = get_schedule(torch.full((num_samples,), t_n, device='cuda'))
        alpha, sigma = get_alpha_sigma(logsnr)
        x0 = alpha.view(-1,1,1,1)*z - sigma.view(-1,1,1,1)*v_pred
        eps = sigma.view(-1,1,1,1)*z + alpha.view(-1,1,1,1)*v_pred
        alpha_n, sigma_n = get_alpha_sigma(logsnr_n)
        z = alpha_n.view(-1,1,1,1)*x0 + sigma_n.view(-1,1,1,1)*eps
    return z.cpu().clamp(0, 1)

def plot_detailed_loss(df_naive, df_fact, logger):
    """
    Generates a grid dynamically based on resolutions found in history.
    Rows: Resolution
    Cols: Dataset Type
    """
    df_naive = df_naive.interpolate()
    df_fact = df_fact.interpolate()
    
    resolutions = sorted(df_naive['res'].unique())
    datasets = ['checkerboard', 'torus']
    
    fig, axes = plt.subplots(len(resolutions), len(datasets), 
                            figsize=(12, 4 * len(resolutions)))
    
    # Handle single resolution case (axes is 1D)
    if len(resolutions) == 1: 
        axes = axes.reshape(1, -1)
        
    for r_idx, res in enumerate(resolutions):
        n_res = df_naive[df_naive['res'] == res]
        f_res = df_fact[df_fact['res'] == res]
        
        for d_idx, dtype in enumerate(datasets):
            ax = axes[r_idx, d_idx]
            col_name = f'loss_{dtype}'
            
            roll_win = 20
            
            if col_name in n_res.columns:
                line_n = n_res[col_name].rolling(roll_win).mean()
                ax.plot(n_res['step'], line_n, label='Naive', color='tab:blue', alpha=0.8)
                
            if col_name in f_res.columns:
                line_f = f_res[col_name].rolling(roll_win).mean()
                ax.plot(f_res['step'], line_f, label='Factorized', color='tab:orange', alpha=0.8)
            
            ax.set_title(f"{dtype.capitalize()} @ {res}px")
            ax.set_yscale('log')
            ax.grid(True, which='both', alpha=0.2)
            if r_idx == 0 and d_idx == 0:
                ax.legend()
    
    plt.tight_layout()
    logger.save_figure(fig, "loss_breakdown_res_vs_type")

def plot_sample_grid(samples_list, logger, string="final_samples"):
    """
    Dynamically plots a list of sample batches.
    Args:
        samples_list: List of tuples (Title, TensorBatch)
    """
    num_rows = len(samples_list)
    cols = 8 # Fixed sample count per batch
    
    fig, axes = plt.subplots(num_rows, cols, figsize=(cols * 2, num_rows * 2))
    
    # Handle single row case
    if num_rows == 1:
        axes = axes.reshape(1, -1)
    
    for r, (name, batch) in enumerate(samples_list):
        for c in range(cols):
            if c < batch.shape[0]:
                axes[r, c].imshow(batch[c].permute(1,2,0).cpu().numpy())
            axes[r, c].axis('off')
            if c == 0: 
                axes[r, c].set_title(name, fontsize=10, loc='left')
            
    plt.suptitle("Unconditional Generation (Mixed Distribution)", fontsize=16)
    plt.tight_layout()
    logger.save_figure(fig, string)

def logsnr_to_alpha_sigma(logsnr):
    """Convert log(SNR) to (alpha, sigma) for noise schedule."""
    # logsnr = log(alpha^2 / sigma^2)
    # SNR = alpha^2 / sigma^2
    snr = torch.exp(logsnr)
    # alpha^2 = SNR / (1 + SNR), sigma^2 = 1 / (1 + SNR)
    alpha_sq = snr / (1.0 + snr)
    sigma_sq = 1.0 / (1.0 + snr)
    return torch.sqrt(alpha_sq), torch.sqrt(sigma_sq)

def sample_logsnr_triplet(batch_size, device, min_logsnr=-10.0, max_logsnr=0.0, min_gap=1.0):
    """
    Sample three noise levels at least min_gap apart.
    Returns: (logsnr_low, logsnr_mid, logsnr_high) where low > mid > high
    """
    # Sample lowest (least noisy, highest logsnr)
    logsnr_low = torch.rand(batch_size, device=device) * (max_logsnr - min_logsnr) + min_logsnr
    
    # Sample mid: 1-4 logsnr units below low
    gap_mid = torch.rand(batch_size, device=device) * 3.0 + min_gap
    logsnr_mid = (logsnr_low - gap_mid).clamp(min=min_logsnr)
    
    # Sample high: 1-4 logsnr units below mid
    gap_high = torch.rand(batch_size, device=device) * 3.0 + min_gap
    logsnr_high = (logsnr_mid - gap_high).clamp(min=min_logsnr)
    
    return logsnr_low, logsnr_mid, logsnr_high

def euler_reverse_step(z_t, v_pred, logsnr_from, logsnr_to):
    """
    Take one deterministic reverse diffusion step using v-prediction.
    
    Args:
        z_t: Current noisy latent [B, C, H, W]
        v_pred: Model's v-prediction [B, C, H, W]
        logsnr_from: Current log(SNR) [B]
        logsnr_to: Target log(SNR) [B]
    
    Returns:
        z_to: Denoised latent at target noise level [B, C, H, W]
    """
    alpha_from, sigma_from = logsnr_to_alpha_sigma(logsnr_from)
    alpha_to, sigma_to = logsnr_to_alpha_sigma(logsnr_to)
    
    # v-prediction: v = alpha * eps - sigma * x0
    # Solve for x0: x0 = (alpha * z_t - sigma * v) / (alpha^2 + sigma^2)
    # But alpha^2 + sigma^2 = 1, so:
    x0_pred = alpha_from.view(-1,1,1,1) * z_t - sigma_from.view(-1,1,1,1) * v_pred
    
    # eps prediction: eps = (sigma * z_t + alpha * v) / (alpha^2 + sigma^2) = sigma * z_t + alpha * v
    eps_pred = sigma_from.view(-1,1,1,1) * z_t + alpha_from.view(-1,1,1,1) * v_pred
    
    # DDIM step (deterministic): z_to = alpha_to * x0_pred + sigma_to * eps_pred
    z_to = alpha_to.view(-1,1,1,1) * x0_pred + sigma_to.view(-1,1,1,1) * eps_pred
    
    return z_to

def compute_consistency_loss(model, x0, spans, mode='factorized', 
                            min_logsnr=-10.0, max_logsnr=0.0):
    """
    Compute trajectory consistency loss.
    
    Strategy:
    1. Sample triplet (logsnr_low, logsnr_mid, logsnr_high)
    2. Add noise to x0 at logsnr_low (most noisy in this triplet)
    3. Generate 1-step trajectory: low ‚Üí high
    4. Generate 2-step trajectory: low ‚Üí mid ‚Üí high
    5. Minimize ||z_high_1step - z_high_2step||
    6. Also minimize ||z_mid_1step - z_mid_2step|| (optional, for stability)
    """
    device = x0.device
    batch_size = x0.shape[0]
    
    # Sample noise levels
    logsnr_low, logsnr_mid, logsnr_high = sample_logsnr_triplet(
        batch_size, device, min_logsnr, max_logsnr
    )
    
    # Add noise at logsnr_low
    alpha_low, sigma_low = logsnr_to_alpha_sigma(logsnr_low)
    eps = torch.randn_like(x0)
    z_low = alpha_low.view(-1,1,1,1) * x0 + sigma_low.view(-1,1,1,1) * eps
    
    # === 1-STEP TRAJECTORY: low ‚Üí high ===
    raw_low, l_pred_low, _ = model(z_low, logsnr_low, spans)
    
    if mode == 'factorized':
        sigma_p_low = torch.sqrt(torch.sigmoid(-l_pred_low)).view(-1,1,1,1)
        v_pred_low = raw_low * sigma_p_low
    else:
        v_pred_low = raw_low
    
    # Step to high (no grad needed for this trajectory)
    with torch.no_grad():
        z_high_1step = euler_reverse_step(z_low, v_pred_low, logsnr_low, logsnr_high)
    
    # === 2-STEP TRAJECTORY: low ‚Üí mid ‚Üí high ===
    # Step 1: low ‚Üí mid (requires grad for mid prediction)
    z_mid_2step = euler_reverse_step(z_low, v_pred_low, logsnr_low, logsnr_mid)
    
    # Step 2: mid ‚Üí high (this is where we need gradients)
    raw_mid, l_pred_mid, _ = model(z_mid_2step, logsnr_mid, spans)
    
    if mode == 'factorized':
        sigma_p_mid = torch.sqrt(torch.sigmoid(-l_pred_mid)).view(-1,1,1,1)
        v_pred_mid = raw_mid * sigma_p_mid
    else:
        v_pred_mid = raw_mid
    
    z_high_2step = euler_reverse_step(z_mid_2step, v_pred_mid, logsnr_mid, logsnr_high)
    
    # === CONSISTENCY LOSSES ===
    # Main loss: 1-step should match 2-step at high
    loss_high = F.mse_loss(z_high_1step, z_high_2step)
    
    # Optional: Also match at mid (helps stability)
    with torch.no_grad():
        z_mid_1step = euler_reverse_step(z_low, v_pred_low, logsnr_low, logsnr_mid)
    loss_mid = F.mse_loss(z_mid_1step, z_mid_2step)
    
    return loss_high + 0.5 * loss_mid

def distill_multires(model, mode, buckets, steps=1000, embed_dim=256, logger=None):
    """
    Trajectory consistency distillation phase.
    Runs AFTER initial denoising training.
    """
    device = torch.device('cuda')
    print(f"\n--- Distilling: {mode.upper()} ---")
    print(f"    Buckets (Res, Batch): {buckets}")
    print(f"    ‚ö†Ô∏è  Using fp16 + reduced batch size for memory")
    
    # Use lower LR for fine-tuning
    opt = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)
    # Reduce batch sizes by half for memory headroom
    buckets_distill = [(res, max(1, bs // 2)) for res, bs in buckets]
    
    # Configure dataset
    mix_config = {'checkerboard': 0.5, 'torus': 0.5}
    iterator = CompositeIterator(device, config=mix_config)
    
    manager = BucketManager(buckets_distill)
    history = []
    
    # Enable fp16 autocast for memory efficiency
    scaler = torch.amp.GradScaler('cuda')
    
    pbar = tqdm(range(steps), desc=f"distill-{mode}")
    for i in pbar:
        opt.zero_grad()
        res, bs = manager.next_bucket()
        
        # Generate batch
        x0 = iterator.generate_batch(bs, res, num_tiles=4.0)
        labels = iterator.last_labels
        
        spans = get_image_spans(res)
        
        with torch.amp.autocast('cuda'):
            # Compute consistency loss (3 NFE per sample)
            loss_consistency = compute_consistency_loss(
                model, x0, spans, mode=mode,
                min_logsnr=-10.0, max_logsnr=0.0
            )
            
            # Optional: Add small denoising loss to prevent drift
            # (Comment out if you want pure consistency training)
            t = torch.rand(bs, device=device).clamp(0.001, 0.999)
            logsnr = get_schedule(t)
            alpha, sigma = get_alpha_sigma(logsnr)
            
            eps = torch.randn_like(x0)
            z_t = x0 * alpha.view(-1,1,1,1) + eps * sigma.view(-1,1,1,1)
            v_true = alpha.view(-1,1,1,1) * eps - sigma.view(-1,1,1,1) * x0
            
            raw, l_pred, aux_loss = model(z_t, logsnr, spans)
            
            if mode == 'factorized':
                sigma_p = torch.sqrt(torch.sigmoid(-l_pred)).view(-1,1,1,1)
                v_pred = raw * sigma_p
            else:
                v_pred = raw
            
            loss_denoise = F.mse_loss(v_pred, v_true)
            
            # Combined loss (consistency is primary, denoising prevents drift)
            total_loss = loss_consistency + 0.1 * loss_denoise + aux_loss
        
        # Backward with gradient scaling
        scaler.scale(total_loss).backward()
        scaler.step(opt)
        scaler.update()
        
        # Logging
        step_stats = {
            'step': i, 
            'res': res, 
            'loss_consistency': loss_consistency.item(),
            'loss_denoise': loss_denoise.item(),
            'loss_total': total_loss.item()
        }
        history.append(step_stats)
        
        if i % 50 == 0:
            pbar.set_postfix({
                'cons': f'{loss_consistency.item():.4f}',
                'den': f'{loss_denoise.item():.4f}',
                'res': res
            })
    
    return pd.DataFrame(history), model

def plot_distillation_loss(df_naive, df_fact, logger):
    """Plot consistency loss curves."""
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    
    # Consistency loss
    ax = axes[0]
    ax.plot(df_naive['step'], df_naive['loss_consistency'].rolling(20).mean(), 
            label='Naive', color='tab:blue')
    ax.plot(df_fact['step'], df_fact['loss_consistency'].rolling(20).mean(), 
            label='Factorized', color='tab:orange')
    ax.set_title("Trajectory Consistency Loss")
    ax.set_xlabel("Step")
    ax.set_ylabel("Loss")
    ax.set_yscale('log')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Denoising loss (for reference)
    ax = axes[1]
    ax.plot(df_naive['step'], df_naive['loss_denoise'].rolling(20).mean(), 
            label='Naive', color='tab:blue', alpha=0.7)
    ax.plot(df_fact['step'], df_fact['loss_denoise'].rolling(20).mean(), 
            label='Factorized', color='tab:orange', alpha=0.7)
    ax.set_title("Denoising Loss (Auxiliary)")
    ax.set_xlabel("Step")
    ax.set_ylabel("Loss")
    ax.set_yscale('log')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    logger.save_figure(fig, "distillation_loss")

def plot_comparison_grid(samples_before, samples_after, resolutions):
    """
    Create a before/after comparison grid.
    
    Layout:
    - Rows: [Naive 16px Before, Naive 16px After, Fact 16px Before, Fact 16px After, ...]
    - Cols: 8 samples
    """
    num_rows = len(samples_before) + len(samples_after)  # Interleaved
    cols = 8
    
    fig, axes = plt.subplots(num_rows, cols, figsize=(cols * 2, num_rows * 1.5))
    
    row_idx = 0
    for i, (name_before, batch_before) in enumerate(samples_before):
        name_after, batch_after = samples_after[i]
        
        # Plot "Before" row
        for c in range(cols):
            if c < batch_before.shape[0]:
                axes[row_idx, c].imshow(batch_before[c].permute(1,2,0).cpu().numpy())
            axes[row_idx, c].axis('off')
            if c == 0:
                axes[row_idx, c].set_title(f"{name_before}\n(Before)", 
                                          fontsize=9, loc='left')
        row_idx += 1
        
        # Plot "After" row
        for c in range(cols):
            if c < batch_after.shape[0]:
                axes[row_idx, c].imshow(batch_after[c].permute(1,2,0).cpu().numpy())
            axes[row_idx, c].axis('off')
            if c == 0:
                axes[row_idx, c].set_title(f"{name_after}\n(After)", 
                                          fontsize=9, loc='left', color='green')
        row_idx += 1
    
    plt.suptitle("Trajectory Consistency Distillation: Before vs After", fontsize=16)
    plt.tight_layout()
    return fig

if __name__ == "__main__":
    torch.set_float32_matmul_precision('high')
    logger = ExperimentLogger(output_dir="./experiments_mix")

    # --- Configuration ---
    # Define resolutions and batch sizes here
    #BUCKETS = [(16, 256), (32, 64), (64, 16)] 
    BUCKETS = [(16, 256), (32, 64), (64, 16)] 
    STEPS = 4000
    DISTILL_STEPS = 2000  # NEW: Distillation steps
    DEPTH = 4
    EMBED_DIM = 256
    
    # Extract resolutions list for convenience
    RESOLUTIONS = [res for (res, bs) in BUCKETS]
    
    # 1. Verify Data Mix
    print("\nüì∏ Verifying Composite Data...")
    iterator = CompositeIterator(device='cuda', config={'checkerboard': 0.5, 'torus': 0.5})
    fig_data = visualize_dataset_samples(iterator, RESOLUTIONS)
    logger.save_figure(fig_data, "dataset_mix_verification")
    
    # 2. Train Models
    df_n, mod_n = train_multires('naive', buckets=BUCKETS, steps=STEPS, 
                                 depth=DEPTH, embed_dim=EMBED_DIM, logger=logger)
    df_f, mod_f = train_multires('factorized', buckets=BUCKETS, steps=STEPS, 
                                 depth=DEPTH, embed_dim=EMBED_DIM, logger=logger)
    
    # 3. Analyze Losses
    print("\nüìà Plotting breakdown...")
    plot_detailed_loss(df_n, df_f, logger)
    
    # 4. Generate and Plot Samples Dynamically
    print("\nüé® Sampling...")
    
    # Collect all samples in a list of tuples: [("Naive 16px", img), ("Fact 16px", img), ...]
    samples_to_plot = []
    
    for res in RESOLUTIONS:
        # Generate samples for this resolution
        s_n = sample_viz(mod_n, res)
        s_f = sample_viz(mod_f, res)
        
        # Append to plot list
        samples_to_plot.append((f"Naive {res}px", s_n))
        samples_to_plot.append((f"Fact {res}px", s_f))
    
    # Plot everything
    plot_sample_grid(samples_to_plot, logger, "unsupervised_samples")
    
    # ========================================
    # 5. DISTILLATION PHASE (NEW)
    # ========================================
    print("\nüîÆ Phase 2: Trajectory Consistency Distillation")
    
    df_n_dist, mod_n = distill_multires(
        mod_n, 'naive', buckets=BUCKETS, steps=DISTILL_STEPS, 
        embed_dim=EMBED_DIM, logger=logger
    )
    
    df_f_dist, mod_f = distill_multires(
        mod_f, 'factorized', buckets=BUCKETS, steps=DISTILL_STEPS,
        embed_dim=EMBED_DIM, logger=logger
    )
    
    # 6. Plot Distillation Losses
    print("\nüìà Plotting distillation losses...")
    plot_distillation_loss(df_n_dist, df_f_dist, logger)
    
    # 7. Sample AFTER Distillation
    print("\nüé® Sampling (After Distillation)...")
    samples_after = []
    for res in RESOLUTIONS:
        s_n = sample_viz(mod_n, res)
        s_f = sample_viz(mod_f, res)
        samples_after.append((f"Naive {res}px", s_n))
        samples_after.append((f"Fact {res}px", s_f))
    
    plot_sample_grid(samples_after, logger, "self_supervised_samples")
    
    # 8. COMPARISON PLOT (Before vs After)
    print("\nüî¨ Generating before/after comparison...")
    
    # Reload pre-distillation samples for side-by-side
    # (Already stored in samples_to_plot)
    
    comparison_samples = []
    for i, (name, batch) in enumerate(samples_to_plot):
        comparison_samples.append((f"{name} (Before)", batch))
        comparison_samples.append((f"{samples_after[i][0]} (After)", samples_after[i][1]))
    
    # Create comparison grid
    fig_compare = plot_comparison_grid(samples_to_plot, samples_after, RESOLUTIONS)
    logger.save_figure(fig_compare, "before_after_comparison")
    
    print(f"\n‚úÖ Done. Check {logger.run_dir}")